{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Word Embedding: Mejorar la representación vectorial de los textos tomando en cuenta las relaciones semánticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivación: representar las dimensiones semánticas de cada palabra\n",
    "\n",
    "1. I want an orange juice.\n",
    "2. I want an apple ____ .\n",
    "\n",
    "- Los enfoques <i>bag of words</i> no tienen la capacidad de calcular que las frases 1 y 2 son muy similares porque no tienen una manera de representar que las palabras 'orange' y 'apple' comparten caracterícas (<i>features</i>) comunes.\n",
    "\n",
    "Los enfoques ingenuos tieden a representar las palabras como vectores \"1-Hot\". Por ejemplo, supongamos que tenemos un vocabulario de sólo cinco palabras: King, Queen, Man, Woman y Child. Se codificaría la palabra 'Queen' como:\n",
    "\n",
    "<img src=\"img/word2vec1.png\"/>\n",
    "\n",
    "- Sería más interesante poder representar la semántica de cada palabra tomando en cuentas ciertas características. \n",
    "\n",
    "<img src=\"img/word2vec2.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Definición\n",
    "\n",
    "El concepto de **word embedding** se refiere a un conjunto de técnicas utilizadas para aprender representaciones matemáticas, tipicamente vectores, de cada palabra.\n",
    "\n",
    "Una de las técnicas más populares es __Word2Vec__ propuesto por un equipo de investigación de Google en 2013 (Efficient Estimation of Word Representations in Vector Space [Mikolov et al., 2013]).\n",
    "\n",
    "Alternativas populares son __GloVe__ (propuesta por la Universidad de Stanford en 2014) y __FastText__ (propuesta por Facebook en 2016), que extende Word2Vec para considerar de mejor manera las palabras con errores ortográficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Algunas propiedades de los word embeddings\n",
    "\n",
    "- Tener representaciones vectoriales de las palabras permite calcular \"razonamiento\" de tipo __King - Man + Woman = ?__ y llegar a un resultado cerca de __Queen__.\n",
    "\n",
    "<img src=\"img/word2vec4.png\"/>\n",
    "\n",
    "- Tener representaciones vectoriales de las palabras permite realizar razonamientos analógicos de tipo __A es a B, lo que C es a ..__ . Este tipo de propiedades es muy útil para aplicaciones de _Question Answering_ por ejemplo. Las respuestas a las pregutas siguientes <i>¿Cuál es la capital de Chile?</i> o <i>¿Cuáles son los clubs de fútbol en Chile?</i> se pueden responder adicionando vectores.\n",
    "\n",
    "<img src=\"img/word2vec6.png\"/>\n",
    "\n",
    "<img src=\"img/word2vec7.png\"/>\n",
    "\n",
    "<img src=\"img/word2vec8.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir sus vectores, Word2Vec utiliza un dataset de entrenamiento y algoritmos de aprendizaje basados en redes neuronales (__Continuous Bag of Words__ (CBOW), o modelo __Skip Gram__). El objetivo de esta fase de aprendizaje es aprender cuáles son las palabras _X_ más probables de aparecer en el contexto de una palabra _y_.\n",
    "\n",
    "<img src=\"img/word2vec5.png\"/>\n",
    "\n",
    "Por ejemplo, ¿cuál es la probabilidad de tener la palabra 'perro' si aparece la palabra 'pelota' en el contexto?\n",
    "\n",
    "<code>Los expertos explican que los __perros__ persiguen __pelotas__ en movimiento como parte de un comportamiento instintivo. Aunque no todos los perros tienen tan despiertos su instinto de caza, esto no impide que la mayoría de ellos sí disfruten, y mucho, de los juegos que incluyen persecuciones de una saltarina __pelota__ que bota delante de ellos. </code>\n",
    "\n",
    "__Algoritmo CBOW__\n",
    "\n",
    "Las palabras de contexto forman la capa de entrada. Si el tamaño del vocabulario es V, estos serán vectores de dimensión V con sólo uno de los elementos establecido en uno, y el resto todos los ceros. Hay una sola capa oculta y una capa de salida.\n",
    "\n",
    "<img src=\"img/word2vec9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejemplo de Word Embedding en Python (con Gensim)\n",
    "\n",
    "La clase <code>word2vec</code> de Gensim permite word embeddings de palabras (ver documentación: https://radimrehurek.com/gensim/models/word2vec.html).\n",
    "\n",
    "Esta clase tiene varios parametros, en particular:\n",
    "- <code>sentences</code>: una lista de palabras o de frases que sirve para entrenar el modelo\n",
    "- <code>sg</code>: define que algoritmos de aprendizaje utilizar (0=CBOW, 1=skip-gram)\n",
    "- <code>size</code>: define la dimensión de los vectores que se desea extraer\n",
    "- <code>window</code>: define el número de palabras considerar a la izquierda y a la derecha de una palabra\n",
    "- <code>min_count</code>: ignorar las palabras que aparecen menos de _min_count_\n",
    "y otros asociados a la parametrización de la fase de aprendizaje de la red neuronal (que no detallaremos en esta parte del curso):\n",
    "- <code>alpha</code>: el _learning rate_ utilizado para optimizar los parametros de la red neuronal.\n",
    "- <code>iter</code>: número de iteraciones (epocas) sobre el dataset para encontrar los parametreos que optimizan la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('datos/text8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences,size=200,hs=1)\n",
    "#model=word2vec.Word2Vec.load(\"text8_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"text8_model\")\n",
    "model=word2vec.Word2Vec.load(\"text8_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=71290, size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.5620756149291992),\n",
       " ('throne', 0.5534422397613525),\n",
       " ('regent', 0.5253190994262695),\n",
       " ('isabella', 0.5218691229820251),\n",
       " ('empress', 0.5112246870994568)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman','king'],negative=['man'],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clashes', 0.6951584815979004),\n",
       " ('conflicts', 0.6921702027320862),\n",
       " ('confrontation', 0.6602897644042969),\n",
       " ('hostilities', 0.6406719088554382),\n",
       " ('struggle', 0.6317054033279419),\n",
       " ('tensions', 0.6200854778289795),\n",
       " ('confrontations', 0.6106060147285461),\n",
       " ('disputes', 0.601070761680603),\n",
       " ('dispute', 0.5880026817321777),\n",
       " ('strife', 0.5856019258499146)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"conflict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confrontation', 0.6138920783996582),\n",
       " ('warfare', 0.5560401082038879),\n",
       " ('weapons', 0.529255211353302),\n",
       " ('fighting', 0.5263172388076782),\n",
       " ('conflicts', 0.5184081792831421),\n",
       " ('pistol', 0.512715220451355),\n",
       " ('warheads', 0.5096693634986877),\n",
       " ('assault', 0.4955317974090576),\n",
       " ('clashes', 0.4931451380252838),\n",
       " ('struggle', 0.49076008796691895)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"conflict\",\"weapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clashes', 0.4917221665382385),\n",
       " ('conflicts', 0.45864203572273254),\n",
       " ('disagreements', 0.4525034427642822),\n",
       " ('disputes', 0.4470274746417999),\n",
       " ('tensions', 0.43743643164634705),\n",
       " ('hostilities', 0.4324764609336853),\n",
       " ('reconciliation', 0.4302550256252289),\n",
       " ('negotiations', 0.42687636613845825),\n",
       " ('dispute', 0.422853022813797),\n",
       " ('strife', 0.41570529341697693)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"conflict\"],negative=[\"weapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('childhood', 0.5351325273513794),\n",
       " ('lives', 0.5025249123573303),\n",
       " ('career', 0.49570488929748535),\n",
       " ('experiences', 0.47748303413391113),\n",
       " ('teens', 0.4545215666294098),\n",
       " ('genius', 0.4330507516860962),\n",
       " ('work', 0.4302922785282135),\n",
       " ('humanity', 0.4295467138290405),\n",
       " ('intellect', 0.4159848690032959),\n",
       " ('adolescence', 0.41503143310546875)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"life\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('childhood', 0.3839266002178192),\n",
       " ('recounting', 0.36995333433151245),\n",
       " ('experiences', 0.35863131284713745),\n",
       " ('incarnations', 0.33248966932296753),\n",
       " ('incarnation', 0.321285605430603),\n",
       " ('retelling', 0.3173801898956299),\n",
       " ('adolescence', 0.31677621603012085),\n",
       " ('conception', 0.31466156244277954),\n",
       " ('lives', 0.3073475956916809),\n",
       " ('manifestation', 0.30052706599235535)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"life\"],negative=[\"money\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver los parametros aprendidos por la red neuronal para una palabra dada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.1952833e-01,  1.1148246e-01,  6.9580138e-01, -2.5740319e-01,\n",
       "        4.7186688e-01,  1.0890626e+00,  7.8428811e-01,  1.2575428e+00,\n",
       "       -3.2528302e-01, -5.9351665e-01, -2.0826530e+00,  3.5133177e-01,\n",
       "       -9.4672424e-01,  2.2377522e+00,  2.5126532e-01,  9.9040347e-01,\n",
       "        4.0315992e-01, -1.3104205e+00,  1.2499611e+00, -3.7213158e-02,\n",
       "        3.6723572e-01,  6.5381400e-02, -6.4698070e-01, -8.3988988e-01,\n",
       "       -1.7005359e-01, -6.4206636e-01, -4.9831229e-01,  1.4915508e-01,\n",
       "        1.5017015e+00,  1.1041881e+00,  4.4298092e-01, -8.4363335e-01,\n",
       "        5.3172308e-01,  2.0636346e+00, -9.7007346e-01,  1.5372264e-01,\n",
       "       -2.2156003e+00,  1.2702472e+00,  1.4431497e+00,  8.2726759e-01,\n",
       "        1.1144599e+00, -2.8155036e-02, -6.1116415e-01,  1.0096577e+00,\n",
       "        1.2654163e-03,  7.8814006e-01, -2.5798957e+00, -2.3802340e+00,\n",
       "       -1.4076350e+00,  1.7053335e+00,  7.3089552e-01,  5.7254595e-01,\n",
       "       -5.8497757e-01,  3.4365246e-01,  1.1702532e+00, -3.4459218e-01,\n",
       "       -7.4192929e-01,  3.0670199e-01, -6.4309245e-01, -8.0701983e-01,\n",
       "       -7.4397868e-01,  5.7604629e-01,  2.8117279e-02, -4.2448312e-01,\n",
       "        5.6171530e-01, -1.7418802e+00,  4.3720305e-01, -7.5061941e-01,\n",
       "        3.7226713e-01, -7.0623159e-02,  5.2516602e-02,  9.2259306e-01,\n",
       "        4.3600172e-01,  1.4143157e-01,  5.2141833e-01, -1.7126353e-01,\n",
       "        2.9692253e-01,  1.1655837e+00,  1.0051504e+00, -6.7928833e-01,\n",
       "        5.9408826e-01,  1.3072983e+00, -1.1347361e+00,  7.8027409e-01,\n",
       "       -1.1938558e+00, -3.4870559e-01, -4.3188125e-01,  1.1319194e+00,\n",
       "        2.8586718e-01, -1.0808007e+00, -4.7473234e-01,  9.7667730e-01,\n",
       "        3.8156822e-01,  6.5179408e-01,  8.1379479e-01, -7.6536924e-01,\n",
       "        1.1998881e+00, -1.1841398e+00, -2.3931956e-01,  1.5629384e-01,\n",
       "       -1.1383122e+00,  2.1788640e+00,  8.5118192e-01, -1.7952284e+00,\n",
       "       -4.0330568e-01,  4.8221114e-01,  5.8959460e-01, -8.2113570e-01,\n",
       "       -1.0437673e+00, -2.1464399e-01,  7.5713468e-01,  4.9011901e-01,\n",
       "        1.9455257e-01,  2.1241301e-01, -9.7648335e-01, -6.4675026e-02,\n",
       "       -1.5499064e-01, -8.9976126e-01, -1.0077031e-01, -3.0446436e-02,\n",
       "        1.0874639e+00, -1.1212444e+00,  1.0957556e+00,  1.7806849e+00,\n",
       "        9.5032245e-01, -1.0155261e+00,  1.9546701e-01, -1.1251221e+00,\n",
       "       -1.4575334e-01, -7.6342684e-01, -1.7241245e-02, -8.0012625e-01,\n",
       "        2.6233810e-01, -1.4262621e+00,  6.7272767e-02,  5.7828914e-02,\n",
       "       -6.4728671e-01, -1.2746649e+00,  1.2287260e+00,  1.3374016e+00,\n",
       "       -1.4076927e-01,  1.0812523e+00, -6.3325179e-01, -1.6353072e+00,\n",
       "        1.3311781e+00,  8.9972429e-02, -3.9910981e-01,  3.1716195e-01,\n",
       "       -1.0974238e+00, -9.1699398e-01,  4.3605012e-01,  2.7587211e+00,\n",
       "        1.3481976e+00, -7.7799976e-01,  4.3714944e-01,  5.6803641e-03,\n",
       "       -6.2780637e-01, -2.0831569e-01,  4.0394747e-01,  7.6370674e-01,\n",
       "       -8.7577301e-01,  3.8893202e-01, -1.4717330e-01,  3.7044996e-01,\n",
       "       -4.6899951e-01,  6.9794858e-01,  4.6818808e-02,  3.6530674e-01,\n",
       "       -2.1127394e-01, -1.1212502e+00,  1.4642909e-01, -2.3815487e-01,\n",
       "       -3.3911458e-01,  7.1420449e-01,  3.9744473e-01, -5.8083469e-01,\n",
       "       -9.0883118e-01,  6.2056959e-02,  5.1958561e-01, -3.8543180e-01,\n",
       "       -9.4180101e-01,  5.7533443e-01, -2.0191398e-02,  7.8437108e-01,\n",
       "        1.1943146e-01, -1.8607596e-01,  1.9412308e+00,  4.7703657e-01,\n",
       "       -3.6369151e-01, -1.2726619e+00, -1.7047827e+00, -4.7039834e-01,\n",
       "       -2.3039560e-01, -6.2429243e-01,  1.0466713e+00,  3.4254158e-01,\n",
       "        4.1798222e-01,  6.0023469e-01, -3.6063284e-02, -4.0839019e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvernier/miniconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"brazil chile france peru argentina\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hammer'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"apple pear banana hammer\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22704087"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man','hammer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14314103"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman','hammer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14349055"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man','engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07078395"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman','engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33093974"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man','baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4592277"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman','baby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Limitaciones\n",
    "\n",
    "Las técnicas de Word Embeddings dan resultados muy interesantes pero tienen dos principales limitaciones:\n",
    "\n",
    "\n",
    "1) **Capturan los estereotipos culturales**. Puede generar problemas éticos de sesgos y injusticias, si se hace una confianza ciega en los modelos predictivos.\n",
    "\n",
    "\n",
    "2) No permiten tomar en cuenta que ciertas **palabras cambian de significado según el contexto**.\n",
    "\n",
    "Ejemplo: \"I lost my computer __mouse__\"\n",
    "\n",
    "\n",
    "3) No permiten tomar en cuenta **el orden entre las palabras**.\n",
    "\n",
    "Ejemplo: \"Estamos aqui para trabajar y no jugar\" vs. \"Estamos aqui para jugar y no trabajar\"\n",
    "\n",
    "\n",
    "\n",
    "Para mejorar estas limitaciones:\n",
    "\n",
    "- Utilizar modelos predictivos que toman en cuenta el contexto de las palabras\n",
    "\n",
    "- Utilizar modelos predictivos que toman en cuenta el orden entre las palabras\n",
    "\n",
    "--> **Redes neuronales convolucionales** (CNN) y **Redes neuronales transformers** (BERT, GPT-2, GPT-3, etc.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
